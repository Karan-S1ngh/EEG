# EEG Dream Emotion Analysis Project

## 📖 Overview

This project explores the relationship between brain activity (EEG), pre-sleep stimuli (videos), dream content (text reports), and subjective dream emotions using the DEED (Dream Emotion Evaluation Dataset). It includes data processing pipelines, multiple machine learning models for emotion prediction, statistical analyses, and an interactive Streamlit dashboard to visualize the findings.


--


## 📊 Dataset

The project utilizes the **DEED dataset**:
* **Paper:** [DEED: A Dataset for Dream-related Emotion Research (bioRxiv)](https://www.biorxiv.org/content/10.1101/2022.09.19.508475v1.full)
* **Download:** [http://www.deeddataset.com//download#/download](http://www.deeddataset.com//download#/download)

The raw data consists of:
1.  `.mat` files containing segmented EEG recordings from REM sleep.
2.  Excel/CSV files containing metadata: participant IDs, dream text reports, dream emotion labels, video stimuli information, and recording timestamps.


---


## 📁 Project Structure
final_year_project/
│
├── eeg_mat_files/                 # .mat EEG recordings (Original raw data)
│
│── 📜 Emotional_ratings_excel_files.xlsx   # Original file: Dream content and emotion labels
│── 📜 Status_identification_of_each_stage_of_EEG.xlsx  # Original file: Experiment timings (start recording, etc.)
│── 📜 Video_list.xlsx                      # Original file: Video stimuli info (name, type)
│
├── 📁 saved_models/                   # Trained ML/DL models & preprocessing objects (.pkl)
│
├── 📁 saved_plots/                    # Plots and visualizations generated by analysis scripts (.png)
| 
├── 📜 master_logbook.csv              # Intermediate merged metadata file
├── 📜 dream_features.csv              # Final clean dataset containing EEG features + emotion labels
│
├── 📜 data_loader.py                  # Loads and merges raw CSV metadata → master_logbook.csv
├── 📜 eeg_processor.py                # Processes .mat EEG data, cleans signals, extracts 30 statistical & frequency features
├── 📜 build_features.py               # Runs EEG processing pipeline on all subjects → dream_features.csv
│
│── 📜 analysis_emotion.py            # 3-Class EEG-based emotion prediction model
├── 📜 analysis_emotion_2class.py     # 2-Class (Calm-focused) EEG model
│── 📜 analysis_nlp_emotion.py        # 3-Class NLP emotion model (TF-IDF features)
│── 📜 analysis_nlp_sentiment.py      # 3-Class NLP sentiment model (VADER-based)
│── 📜 analysis_multimodal.py         # 2-Class multimodal model combining EEG + NLP
│── 📜 analysis_multimodal_3class.py         # 3-Class multimodal model combining EEG + NLP
│
├── 📜 analysis_video.py               # Project 2: Video stimulus impact analysis and visualization
├── 📜 analysis_content.py             # Project 3: Content correlation (NLP-based) and heatmap generation
│
├── 📜 app.py                          # Streamlit dashboard for visualization & model interaction
│
└── 📜 README.md                       # This documentation file


---


## ⚙️ Setup

1.  **Clone the repository** (or download the files).
2.  **Place Data:**
    * Put the original metadata CSV files (renamed from Excel) in the main project folder.
    * Create the `data/eeg_mat_files/` directory and place all your `.mat` files inside it.
3.  **Install Dependencies:** It's recommended to use a virtual environment.
    ```bash
    pip install pandas openpyxl numpy scipy mne scikit-learn joblib tqdm matplotlib seaborn streamlit vaderSentiment xgboost imbalanced-learn
    ```
    *(Note: `xgboost` and `imbalanced-learn` were used in earlier experiments but might not be strictly necessary for the final best models.)*


---


## ▶️ How to Run

Execute the scripts in the following order from your terminal in the main project directory:

1.  **Prepare Metadata:**
    ```bash
    python data_loader.py
    ```
    *Output: `master_logbook.csv`*

2.  **Prepare EEG Features:**
    ```bash
    python build_features.py
    ```
    *Input: `master_logbook.csv`, `data/eeg_mat_files/*.mat`*
    *Output: `dream_features.csv`*
    *(This takes several minutes)*

3.  **Run Analyses (Optional but Recommended):** Run scripts to generate models/plots.
    ```bash
    # Run your best emotion model (multimodal)
    python analysis_emotion_scripts/analysis_multimodal.py
    # Output: saves multimodal_model.pkl in saved_models/

    # Run video impact analysis
    python analysis_video.py
    # Output: saves video_impact_plot.png in saved_plots/

    # Run content correlation analysis
    python analysis_content.py
    # Output: saves content_correlation_heatmap.png in saved_plots/
    ```
    *(You can run the other emotion scripts too if you want to regenerate those models.)*

4.  **Launch the Streamlit Dashboard:**
    ```bash
    streamlit run app.py
    ```
    *This will open the interactive dashboard in your web browser.*


---


## ✨ Key Findings

* **Emotion Prediction:** Predicting dream emotion is challenging. Models using only EEG achieved ~61% accuracy (Calm vs. Not Calm), while NLP models achieved ~55%. However, a **multimodal model combining EEG and dream text achieved 93.5% accuracy**, highlighting the benefit of integrating data sources.
* **Video Impact:** Pre-sleep video content showed a **statistically significant impact** on EEG features during dreams, particularly in alpha and theta bands in frontal channels (example finding - adjust based on your `analysis_video.py` output).
* **Content Correlation:** While direct correlations between specific dream keywords and EEG band power were generally weak, a heatmap revealed subtle patterns (example finding - adjust based on your `analysis_content.py` output).
